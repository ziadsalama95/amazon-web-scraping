{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Amazon Product Scraper\n\nThis notebook demonstrates a web scraping tool designed to extract product data from Amazon Egypt.","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## Importing Libraries and Fetching Functions\n\nThis section imports all the necessary libraries, including `requests`, `pandas`, `BeautifulSoup` and a custom `functions.py` file from my GitHub repository.","metadata":{"tags":[]}},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport random\nimport requests\nresponse = requests.get(\"https://raw.githubusercontent.com/ziadsalama95/amazon-web-scraping/main/functions.py\")\nwith open(\"functions.py\", \"wb\") as file:\n    file.write(response.content)\nimport functions as fn\nimport pandas as pd\nfrom bs4 import BeautifulSoup","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting the Amazon URL\n\nHere, we define the base URL for Amazon Egypt's search page. This URL will be used as the starting point for scraping data.","metadata":{"tags":[]}},{"cell_type":"code","source":"url = 'https://www.amazon.eg/s'","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining User Agents and Search Terms\n\nWe define a list of user agents to mimic requests from various browsers and devices. This helps avoid detection by the website as a bot. Additionally, a comprehensive list of search terms is defined, which will be used to query Amazon's search page. The maximum number of results to retrieve is also set.","metadata":{}},{"cell_type":"code","source":"user_agents = [\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:113.0) Gecko/20100101 Firefox/113.0\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:112.0) Gecko/20100101 Firefox/112.0\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Version/13.0 Safari/537.36\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:113.0) Gecko/20100101 Firefox/113.0\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edge/113.0.0.0\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; Trident/7.0; AS; rv:11.0) like Gecko\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 OPR/94.0.0.0\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 OPR/93.0.0.0\", \"Mozilla/5.0 (Android 13; Mobile; rv:113.0) Gecko/113.0 Firefox/113.0\", \"Mozilla/5.0 (Android 12; Mobile; rv:112.0) Gecko/112.0 Firefox/112.0\", \"Mozilla/5.0 (iPhone; CPU iPhone OS 16_2 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Version/16.2 Mobile/15E148 Safari/537.36\", \"Mozilla/5.0 (iPad; CPU OS 16_0 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Version/16.0 Safari/537.36\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:112.0) Gecko/20100101 Firefox/112.0 Edge/112.0.0.0\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:111.0) Gecko/20100101 Firefox/111.0 Edge/111.0.0.0\", \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\", \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\", \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:113.0) Gecko/20100101 Firefox/113.0\", \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:112.0) Gecko/20100101 Firefox/112.0\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 OPR/91.0.0.0\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 OPR/90.0.0.0\", \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1\", \"Mozilla/5.0 (Android 12; Mobile; rv:113.0) Gecko/113.0 Firefox/113.0 Edge/113.0.0.0\", \"Mozilla/5.0 (Android 11; Mobile; rv:112.0) Gecko/112.0 Firefox/112.0\"]\n\nlist_search = [\"best sellers\", \"hot new releases\", \"top rated\", \"electronics\", \"smartphones\", \"laptops\", \"tablets\", \"smart home devices\", \"wearable technology\", \"home gadgets\", \"kitchen appliances\", \"home decor\", \"furniture\", \"outdoor gear\", \"fitness equipment\", \"yoga mats\", \"sportswear\", \"running shoes\", \"health supplements\", \"beauty products\", \"skincare\", \"haircare\", \"makeup\", \"fragrances\", \"organic products\", \"sustainable products\", \"eco-friendly\", \"baby products\", \"toys\", \"games\", \"puzzles\", \"books\", \"ebooks\", \"audiobooks\", \"office supplies\", \"stationery\", \"craft supplies\", \"art supplies\", \"musical instruments\", \"video games\", \"gaming consoles\", \"board games\", \"travel gear\", \"luggage\", \"backpacks\", \"camping gear\", \"hiking boots\", \"cycling gear\", \"pet supplies\", \"dog toys\", \"cat toys\", \"pet food\", \"car accessories\", \"automotive tools\", \"gardening tools\", \"power tools\", \"hand tools\", \"home improvement\", \"DIY kits\", \"lighting\", \"LED lights\", \"security cameras\", \"headphones\", \"bluetooth speakers\", \"portable chargers\", \"phone accessories\", \"camera gear\", \"drone accessories\", \"VR headsets\", \"smart watches\", \"fitness trackers\", \"electric scooters\", \"e-bikes\", \"3D printers\", \"robot vacuums\", \"air purifiers\", \"humidifiers\", \"space heaters\", \"fans\", \"blenders\", \"coffee makers\", \"air fryers\", \"instant pots\", \"cookware sets\", \"bakeware\", \"cutlery\", \"dishware\", \"glasses\", \"water bottles\", \"wine glasses\", \"storage solutions\", \"organizers\", \"closet systems\", \"laundry baskets\", \"cleaning supplies\", \"bedding\", \"mattresses\", \"pillows\", \"blankets\", \"curtains\"]\n\nmax_results = 1000","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scraping Logic\n\nThis code iterates through a list of search keywords (`list_search`) to scrape product data from Amazon. For each keyword, the script fetches product details such as name, rating, number of reviews and price by parsing the HTML content of the search results page. The scraping continues across multiple pages until the specified number of products (`max_results`) is collected.\n\nTo avoid detection and ensure smooth scraping, the script uses random `User-Agent` headers and includes a delay between requests. The collected data is stored in `total_products`, with progress updates printed throughout the execution.","metadata":{"tags":[]}},{"cell_type":"code","source":"total_products = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for search in list_search:\n    page = 1\n    products = []\n    \n    while len(products) < max_results:\n        \n        try:\n            headers = ({'User-Agent': random.choice(user_agents)})\n            params = {'k': search, 'page': page}\n            response = requests.get(url, headers=headers, params=params)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            continue\n\n        soup = BeautifulSoup(response.content, \"html.parser\")\n        containers = soup.findAll('div', {'class': 'sg-col-4-of-24 sg-col-4-of-12 s-result-item s-asin sg-col-4-of-16 sg-col s-widget-spacing-small sg-col-4-of-20'})\n        \n        if not containers:\n            print(\"No more products found on this page.\")\n            break\n\n        for container in containers:\n            product_name = fn.get_product_name(container)\n            product_rating = fn.get_product_rating(container)\n            product_nreviews = fn.get_product_nreviews(container)\n            product_price = fn.get_product_price(container)\n\n            products.append({\n                'Name': product_name,\n                'Price (EGP)': product_price,\n                'Rating': product_rating,\n                'Reviews': product_nreviews,\n                'Keyword': search,\n            })\n\n            if len(products) >= max_results:\n                break\n\n        total_products.extend(products)\n        print(f\"Got {len(products)} products for: {search} (Page {page})\")\n        page += 1\n        time.sleep(3)\n\n    print(f\"Finished search for: {search}. Total products found: {len(products)}\")\n\nprint(f\"Total products collected: {len(total_products)}\")","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(total_products)\ndf.drop_duplicates(inplace=True)\ndf.reset_index(inplace=True)\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the Data","metadata":{}},{"cell_type":"code","source":"os.makedirs('data', exist_ok=True)\ndf.to_csv('data/products.csv', index=False)\ndf.head()","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}